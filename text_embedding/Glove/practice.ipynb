{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQ0M3iRdN5_E"
      },
      "source": [
        "#### Word2Vec vs FastText"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "4wQoNuU0C7d7"
      },
      "outputs": [],
      "source": [
        "!pip install konlpy\n",
        "!pip install mecab-python\n",
        "!bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S_pS7XJACr_z"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import urllib.request\n",
        "import zipfile\n",
        "from lxml import etree\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uK2RAP-UDvUm"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AkRr-SqzCtp4"
      },
      "outputs": [],
      "source": [
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/ukairia777/tensorflow-nlp-tutorial/main/09.%20Word%20Embedding/dataset/ted_en-20160408.xml\", filename=\"ted_en-20160408.xml\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KH0pdvE9CvVP"
      },
      "outputs": [],
      "source": [
        "# 필요한 데이터인 <content></content> 사이의 내용만 추출\n",
        "targetXML = open('ted_en-20160408.xml', 'r', encoding='UTF8')\n",
        "target_text = etree.parse(targetXML)\n",
        "parse_text = '\\n'.join(target_text.xpath('//content/text()'))\n",
        "\n",
        "content_text = re.sub(r'\\([^)]*\\)', '', parse_text)\n",
        "\n",
        "sent_text = sent_tokenize(content_text)\n",
        "\n",
        "normalized_text = []\n",
        "for string in sent_text:\n",
        "    tokens = re.sub(r\"[^a-z0-9]+\", \" \", string.lower())\n",
        "    normalized_text.append(tokens)\n",
        "\n",
        "result = [word_tokenize(sentence) for sentence in normalized_text]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RSd1PTC8Cww7"
      },
      "outputs": [],
      "source": [
        "print('총 샘플의 수: ', len(result))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hhX2ScjfGSoX"
      },
      "outputs": [],
      "source": [
        "print(result[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9F-2Y_yLGXev"
      },
      "outputs": [],
      "source": [
        "from gensim.models import Word2Vec\n",
        "from gensim.models import KeyedVectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LvAzLxTuGme_"
      },
      "outputs": [],
      "source": [
        "# Word2Vec 하이퍼파라미터\n",
        "# vector_size: 임베딩 된 벡터의 차원\n",
        "# window: 컨텍스트 윈도우 크기\n",
        "# min_count: 단어 최소 빈도 수 제한(min_count 아래의 단어는 학습하지 않는다.)\n",
        "# workers: 학습을 위한 프로세스 수\n",
        "# sg: CBOW=0, SKIP-gram=1\n",
        "model = Word2Vec(sentences=result, vector_size=100, window=5, min_count=5, workers=4, sg=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ldcwjJx_GuyP"
      },
      "outputs": [],
      "source": [
        "# man과 가장 유사한 단어 찾기(wv.most_similar())\n",
        "model_result = model.wv.most_similar(\"man\")\n",
        "print(model_result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x3fJnYp8LlV6"
      },
      "outputs": [],
      "source": [
        "# 모델 저장하고 로드하기\n",
        "model.wv.save_word2vec_format('eng_w2v')\n",
        "loaded_model = KeyedVectors.load_word2vec_format(\"eng_w2v\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZLhXPQMvjZH-"
      },
      "outputs": [],
      "source": [
        "loaded_model.most_similar(\"electrofishing\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kJ9DLzM0kAcL"
      },
      "outputs": [],
      "source": [
        "from gensim.models import FastText\n",
        "\n",
        "model = FastText(result, vector_size=100, window=5, min_count=5, workers=4, sg=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-GKxWvbZkIJ6"
      },
      "outputs": [],
      "source": [
        "model.wv.most_similar(\"electrofishing\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iFKAX_ovkLnb"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
